{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48fvOWEu52yc",
        "outputId": "66cb1c3e-f8d0-4ef4-b131-cfd9a8d41d11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8O6LQ87Sro",
        "outputId": "187583aa-8d56-44b6-ceac-f5e288e18413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmcI1gJy7X6Q"
      },
      "outputs": [],
      "source": [
        "from textwrap import wrap\n",
        "\n",
        "import emoji\n",
        "import joblib\n",
        "import langdetect\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay \n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCB5H7Td7ukc"
      },
      "outputs": [],
      "source": [
        "def get_category_dict(category_file):\n",
        "  category = pd.read_json(category_file, orient=\"records\")\n",
        "  category = pd.DataFrame(category[\"items\"].values.tolist())\n",
        "\n",
        "  return {\n",
        "      cat.id: cat.snippet.get(\"title\")\n",
        "      for cat in category.itertuples(index=False)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVkf0HJ37yJJ"
      },
      "outputs": [],
      "source": [
        "def get_category_dict(category_file):\n",
        "  category = pd.read_json(category_file, orient=\"records\")\n",
        "  category = pd.DataFrame(category[\"items\"].values.tolist())\n",
        "\n",
        "  return {\n",
        "      cat.id: cat.snippet.get(\"title\")\n",
        "      for cat in category.itertuples(index=False)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1vDPI6i706h",
        "outputId": "d707b768-c617-4728-fba7-1370607c8c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (1.0.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVxDtYRU74jg",
        "outputId": "4ddae7ab-59d8-405f-fff2-973124035364"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (2.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DJVgjam78_Y"
      },
      "outputs": [],
      "source": [
        "from textwrap import wrap\n",
        "\n",
        "import emoji\n",
        "import joblib\n",
        "import langdetect\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay \n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KwiYrheZ8BGR"
      },
      "outputs": [],
      "source": [
        "def get_category_dict(category_file):\n",
        "  category = pd.read_json(category_file, orient=\"records\")\n",
        "  category = pd.DataFrame(category[\"items\"].values.tolist())\n",
        "\n",
        "  return {\n",
        "      cat.id: cat.snippet.get(\"title\")\n",
        "      for cat in category.itertuples(index=False)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZEqqgvU8FnI"
      },
      "outputs": [],
      "source": [
        "def get_category_dict(category_file):\n",
        "  category = pd.read_json(category_file, orient=\"records\")\n",
        "  category = pd.DataFrame(category[\"items\"].values.tolist())\n",
        "\n",
        "  return {\n",
        "      cat.id: cat.snippet.get(\"title\")\n",
        "      for cat in category.itertuples(index=False)\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIa2xkKB8JQ4"
      },
      "outputs": [],
      "source": [
        "category_dict = get_category_dict('/content/sample_data/category.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-1MjrJY_8ew"
      },
      "outputs": [],
      "source": [
        "trending = pd.read_csv(\"/content/sample_data/trending.csv\", parse_dates=[\"publish_time\", \"trending_time\"])\n",
        "with pd.option_context(\"display.max_columns\", None):\n",
        "  display(trending.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vofg7pPKTwxu",
        "outputId": "ad78b026-2e29-4dca-c365-89ec9c4c5ab0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start_date =  2021-02-07 05:46:51.832614+00:00\n",
            "start_date =  2021-02-07 05:46:51.832614+00:00\n"
          ]
        }
      ],
      "source": [
        "start_date = trending.trending_time.min()\n",
        "end_date = trending.trending_time.max()\n",
        "\n",
        "print(\"start_date = \", start_date)\n",
        "print(\"start_date = \", start_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUrETCpeT0UI"
      },
      "outputs": [],
      "source": [
        "#delete data dari bulan februari - juni \n",
        "\n",
        "filtered_trending = trending[trending.trending_time.dt.month >= 7]\n",
        "\n",
        "start_date = filtered_trending.trending_time.min()\n",
        "end_date = filtered_trending.trending_time.max()\n",
        "\n",
        "print(\"start_date = \", start_date)\n",
        "print(\"start_date = \", start_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGzgXx2UT4uI"
      },
      "outputs": [],
      "source": [
        "num_videos = filtered_trending.shape[0]\n",
        "print(f'{num_videos :}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4RfHzTkT7xa"
      },
      "outputs": [],
      "source": [
        "# Distribusi Missing Value\n",
        "filtered_trending.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnG2HnoYT--I"
      },
      "outputs": [],
      "source": [
        "# Delete video dengan description kosong\n",
        "filtered_trending.dropna(subset=[\"description\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPi0tC-yUB_H"
      },
      "outputs": [],
      "source": [
        "trending_by_date = filtered_trending.groupby(\n",
        " filtered_trending.trending_time.dt.date\n",
        ")\n",
        "num_trending_per_day = trending_by_date.trending_time.count()\n",
        "print(\"Number of videos in trending per day:\", num_trending_per_day.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yq4-2IgTUFlp"
      },
      "outputs": [],
      "source": [
        "trending_duration = filtered_trending.groupby(\"title\").agg(\n",
        " trending_duration=pd.NamedAgg(column=\"trending_time\", aggfunc=\"count\"),\n",
        " trending_start_date=pd.NamedAgg(column=\"trending_time\", aggfunc=\"min\"),\n",
        " trending_last_date=pd.NamedAgg(column=\"trending_time\", aggfunc=\"max\")\n",
        ").sort_values(\"trending_duration\", ascending=False).reset_index()\n",
        "trending_duration.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEftAbkuUKga"
      },
      "outputs": [],
      "source": [
        "# Visualisasi data trending dengan chart bar\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(\n",
        " trending_duration.title[:10].apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " trending_duration.trending_duration[:10]\n",
        ")\n",
        "plt.title(\"Longest Duration of Videos included in YouTube Trending Video\", loc=\"left\")\n",
        "plt.xlabel(\"Video Title\")\n",
        "plt.ylabel(\"Trending Duration (in days)\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uskvh55UPlo"
      },
      "outputs": [],
      "source": [
        "# Visualisasi data trending dengan chart bar\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(\n",
        " trending_duration.title[:10].apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " trending_duration.trending_duration[:10]\n",
        ")\n",
        "plt.title(\"Longest Duration of Videos included in YouTube Trending Video\", loc=\"left\")\n",
        "plt.xlabel(\"Video Title\")\n",
        "plt.ylabel(\"Trending Duration (in days)\")\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1_n53kVUToC"
      },
      "outputs": [],
      "source": [
        "trending_by_title = filtered_trending.groupby(\"title\")\n",
        "trending_rewind = trending_by_title[[\"view\", \"like\", \"dislike\"]].agg([\"min\", \"max\", \"mean\", \"sum\"])\n",
        "trending_rewind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vPkXQwmUZD5"
      },
      "outputs": [],
      "source": [
        "# Visualisasi Trending video teratas masing2\n",
        "top_10_liked = trending_rewind[\"like\"].sort_values(\"max\", ascending=False).iloc[:10]\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(\n",
        " top_10_liked.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " top_10_liked[\"max\"],\n",
        " label=\"last like\"\n",
        ")\n",
        "plt.bar(\n",
        " top_10_liked.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " top_10_liked[\"min\"],\n",
        " label=\"start like\"\n",
        ")\n",
        "plt.title(\"Most videos in trending list improves drastically in terms of likes\", loc=\"left\", y=1.1)\n",
        "plt.xlabel(\"Number of Like\")\n",
        "plt.ylabel(\"Video Title\")\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6xkerf7UbAx"
      },
      "outputs": [],
      "source": [
        "top_10_viewed = trending_rewind[\"view\"].sort_values(\"max\", ascending=False).iloc[:10]\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(\n",
        "    top_10_viewed.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        "    top_10_viewed[\"max\"],\n",
        "    label=\"last views\"\n",
        ")\n",
        "plt.bar(\n",
        "    top_10_viewed.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        "    top_10_viewed[\"min\"],\n",
        "    label=\"last views\"\n",
        ")\n",
        "plt.title(\"Most videos in trending list improve drastically in terms of views\", loc=\"left\", y=1.1)\n",
        "plt.xlabel(\"Number of Views\")\n",
        "plt.ylabel(\"Video Title\")\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nscd3ZfaUekX"
      },
      "outputs": [],
      "source": [
        "top_10_disliked = trending_rewind[\"dislike\"].sort_values(\"max\", ascending=False).iloc[:10]\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.bar(\n",
        " top_10_disliked.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " top_10_disliked[\"max\"],\n",
        " label=\"last dislike\"\n",
        ")\n",
        "plt.bar(\n",
        " top_10_disliked.index.to_series().apply(lambda title: \"\\n\".join(wrap(title, width=10))),\n",
        " top_10_disliked[\"min\"],\n",
        " label=\"start dislike\"\n",
        ")\n",
        "plt.title(\"Most disliked videos in trending list are of shorts and gain more dislikes\", loc=\"left\", y=1.1)\n",
        "plt.ylabel(\"Number of Dislike\")\n",
        "plt.xlabel(\"Video Title\")\n",
        "plt.legend()\n",
        "plt.grid(False)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mMr3Q4IVG5P"
      },
      "outputs": [],
      "source": [
        "# Sebagai contoh, perhatikan sampel judul dan deskripsi video berikut.\n",
        "sample = filtered_trending.sample(10, random_state=11)\n",
        "sample[[\"title\", \"description\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "culXgxgTVJ2s"
      },
      "outputs": [],
      "source": [
        "# Merubah title dan descripsi video menjadi lowercase\n",
        "sample[\"title_lang\"] = sample.title.apply(lambda title: langdetect.detect(title.lower()))\n",
        "sample[\"desc_lang\"] = sample.description.apply(lambda desc: langdetect.detect(desc.lower()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVCfrj14VNbP"
      },
      "outputs": [],
      "source": [
        "with pd.option_context(\"display.max_colwidth\", 100):\n",
        " display(sample[[\"title\", \"title_lang\", \"description\", \"desc_lang\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl46pQStVTM-"
      },
      "outputs": [],
      "source": [
        "def detect_language(text):\n",
        " \"\"\"Detect language of the `text`.\"\"\"\n",
        " try: \n",
        "  lang = langdetect.detect(text)\n",
        "  return lang\n",
        " except:\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bHNgNzilVWKm"
      },
      "outputs": [],
      "source": [
        "filtered_trending[\"title_lang\"] = filtered_trending[\"title\"].apply(detect_language)\n",
        "filtered_trending[\"desc_lang\"] = filtered_trending[\"description\"].apply(detect_language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjZv8fJ_akxL"
      },
      "outputs": [],
      "source": [
        "filtered_trending[[\"title\", \"title_lang\", \"description\", \"desc_lang\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYOanmqgamX4"
      },
      "outputs": [],
      "source": [
        "indo_trending = filtered_trending.loc[\n",
        " (filtered_trending.title_lang == \"id\") | (filtered_trending.desc_lang == \"id\")\n",
        "]\n",
        "with pd.option_context(\"display.max_columns\", None):\n",
        " display(indo_trending.sample(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP_DxiBhaq1c"
      },
      "outputs": [],
      "source": [
        "data = indo_trending[[\"title\", \"description\", \"category_id\"]].reset_index(drop=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdJ8crUcatqg"
      },
      "outputs": [],
      "source": [
        "data.drop_duplicates(subset=\"title\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0sFDtvKawcI"
      },
      "outputs": [],
      "source": [
        "data.reset_index(drop=True, inplace=True)\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "9c1jyjfDazDc",
        "outputId": "20b58a89-ac61-4788-f5dd-00398f227731"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7b655ff63871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_emoji\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0me\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memoji\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNICODE_EMOJI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_emoji\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'emoji' has no attribute 'UNICODE_EMOJI'"
          ]
        }
      ],
      "source": [
        "list_emoji = [e for e in emoji.UNICODE_EMOJI.get(\"en\")]\n",
        "\n",
        "count = 0\n",
        "for em in list_emoji:\n",
        "  for title in data.title:\n",
        "    if em in title:\n",
        "      count += 1\n",
        "print(\"How many titles use emoji?\", count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0A0vbYNgpIw"
      },
      "outputs": [],
      "source": [
        "def demojize(text):\n",
        " for em in list_emoji:\n",
        " if em in text:\n",
        " em_text = emoji.demojize(em)\n",
        " text = text.replace(em, \" \" + em_text + \" \")\n",
        " return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3DUNiOHguw0"
      },
      "outputs": [],
      "source": [
        "def demojize(text):\n",
        " for em in list_emoji:\n",
        " if em in text:\n",
        " em_text = emoji.demojize(em)\n",
        " text = text.replace(em, \" \" + em_text + \" \")\n",
        " return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TExeJKCfgw9z"
      },
      "outputs": [],
      "source": [
        "data[\"title_emoji\"] = data.title.apply(demojize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwSVTUYkgy00"
      },
      "outputs": [],
      "source": [
        "title_with_emoji_idx = [\n",
        " idx for idx in range(len(data.title))\n",
        " for em in list_emoji\n",
        " if em in data.loc[idx, \"title\"]\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D_4-x4Pg0a7"
      },
      "outputs": [],
      "source": [
        "with pd.option_context(\"display.max_colwidth\", 100):\n",
        " display(data.loc[title_with_emoji_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG20VJGNg2Sd"
      },
      "outputs": [],
      "source": [
        "# Delete kolom title\n",
        "data.drop(columns=\"title\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7K5Vmeng4nd"
      },
      "outputs": [],
      "source": [
        "desc_with_emoji_idx = [\n",
        " idx for idx in range(len(data.description))\n",
        " for em in list_emoji\n",
        " if em in data.loc[idx, \"description\"]\n",
        "]\n",
        "data[\"desc_emoji\"] = data.description.apply(demojize)\n",
        "with pd.option_context(\"display.max_colwidth\", 100):\n",
        " display(data.loc[desc_with_emoji_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcMrNLw1g6di"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=\"description\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkPHAxlOg8d0"
      },
      "outputs": [],
      "source": [
        "data[\"all_text\"] = data[\"title_emoji\"] + \" \" + data[\"desc_emoji\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHzsHZ7Pg-2V"
      },
      "outputs": [],
      "source": [
        "# data split\n",
        "X_train, X_dev, y_train, y_dev = train_test_split(\n",
        " data[\"all_text\"], data[\"category_id\"],\n",
        " test_size=.2,\n",
        " stratify=data[\"category_id\"],\n",
        " random_state=11\n",
        ")\n",
        "training_size = X_train.shape[0]\n",
        "dev_size = X_dev.shape[0]\n",
        "print(f\"{training_size = }.. {dev_size = }\")\n",
        "# define vectorizer\n",
        "vectorizer = TfidfVectorizer(\n",
        " min_df=.015,\n",
        " max_df=.7,\n",
        " ngram_range=(1, 1),\n",
        ")\n",
        "# generate tf-idf matrix\n",
        "train_tfidf = vectorizer.fit_transform(X_train)\n",
        "dev_tfidf = vectorizer.transform(X_dev)\n",
        "print(\"Got train tf-idf with shape:\", train_tfidf.shape)\n",
        "print(\"Got dev tf-idf with shape:\", dev_tfidf.shape)\n",
        "# convert to dataframe\n",
        "train_tfidf = pd.DataFrame(train_tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "dev_tfidf = pd.DataFrame(dev_tfidf.toarray(), columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrylnB5PhOHk"
      },
      "outputs": [],
      "source": [
        "with pd.option_context(\"display.max_columns\", 100):\n",
        " display(train_tfidf.sample(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxRo8jphP2k"
      },
      "outputs": [],
      "source": [
        "dict_models = {\n",
        " \"logistic_regression\": LogisticRegression(),\n",
        " \"naive_bayes\": MultinomialNB(),\n",
        " \"svm\": LinearSVC(random_state=11),\n",
        " \"decision_tree\": DecisionTreeClassifier(random_state=11),\n",
        " \"random_forest\": RandomForestClassifier(random_state=11)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCLdN3SChR8o"
      },
      "outputs": [],
      "source": [
        "for model in dict_models.values():\n",
        " print(f\"-- {model.__class__.__name__} --\")\n",
        " model.fit(train_tfidf, y_train)\n",
        " y_pred = model.predict(dev_tfidf)\n",
        " print(\"Reports on dev set:\", classification_report(y_dev, y_pred), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQG6Inh1hT4X"
      },
      "outputs": [],
      "source": [
        "svm_grid_search = GridSearchCV(\n",
        " dict_models[\"svm\"],\n",
        " {\"C\": (10, 1, .1, .05, .01)},\n",
        ")\n",
        "svm_grid_search.fit(train_tfidf, y_train)\n",
        "svm_pred_dev = svm_grid_search.predict(dev_tfidf)\n",
        "print(\"Reports on train set:\",\n",
        " classification_report(\n",
        " y_train,\n",
        " svm_grid_search.predict(train_tfidf)\n",
        " ), sep=\"\\n\")\n",
        "print(\"Reports on dev set:\", classification_report(y_dev, svm_pred_dev), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5CRAZadhWYK"
      },
      "outputs": [],
      "source": [
        "svm_grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfZKoiF4hYRd"
      },
      "outputs": [],
      "source": [
        "random_forest_grid_search = GridSearchCV(\n",
        " dict_models[\"random_forest\"],\n",
        " {\n",
        " \"n_estimators\": (10, 20, 25, 50, 75, 100, 125),\n",
        " \"max_depth\": (5, 10, 25, 50),\n",
        " }\n",
        ")\n",
        "random_forest_grid_search.fit(train_tfidf, y_train)\n",
        "random_forest_pred = random_forest_grid_search.predict(dev_tfidf)\n",
        "print(\"Reports on train set:\",\n",
        " classification_report(\n",
        " y_train,\n",
        " random_forest_grid_search.predict(train_tfidf)\n",
        " ),\n",
        " sep=\"\\n\"\n",
        ")\n",
        "print(\"Reports on dev set:\", classification_report(y_dev, random_forest_pred), sep=\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXvoCvVwhaqU"
      },
      "outputs": [],
      "source": [
        "random_forest_grid_search.best_params_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3UVBs-bhdR2"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        " (\"vectorizer\", TfidfVectorizer(\n",
        " min_df=.015,\n",
        " max_df=.7,\n",
        " ngram_range=(1, 1),\n",
        " )),\n",
        " (\"model\", RandomForestClassifier(\n",
        " max_depth=50,\n",
        " n_estimators=75,\n",
        " random_state=11\n",
        " ))\n",
        "])\n",
        "# training\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_dev)\n",
        "print(\"Reports on train set:\",\n",
        " classification_report(\n",
        " y_train,\n",
        " model.predict(X_train)\n",
        " ),\n",
        " sep=\"\\n\"\n",
        ")\n",
        "print(\"Reports on dev set:\", classification_report(y_dev, pred), sep=\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IeR8ukQhfcw"
      },
      "outputs": [],
      "source": [
        "joblib.dump(model, \"D:/PTA 2016-2017/Modul/dataset/modelyt.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3S2l7dNuhidD"
      },
      "outputs": [],
      "source": [
        "model = joblib.load(\"D:/PTA 2016-2017/Modul/dataset/modelyt.joblib\")\n",
        "print(model.get_params())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = model.predict(X_dev)\n",
        "print(classification_report(y_dev, preds))"
      ],
      "metadata": {
        "id": "_BGL_DQXVvu8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}